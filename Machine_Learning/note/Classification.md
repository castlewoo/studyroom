# 분류

## 분류 성능  평가 지표
- 정확도(Accuracy)
- 오차행렬(Confusion Matrix)
- 정밀도(Precision)
- 재현율(Recall)
- F1 스코어
- ROC AUC

### 정확도
- 직관적으로 모델 예측 성능르 나타내는 평가 지표
- 이진 분류의 경우 모델의 성능을 왜곡할 수 있기 때문에 수치 하나만 가지고 성능 평가 X
- 불균형한 레이블 값 분포에서 모델의 성능을 판단할 경우, 적합한 평가 지표 X


### 오차 행렬
- 이진 분류의 예측 오류가 얼마인지, 어떤 유형의 예측 오류가 발생하는지 나타내는 지표
- TN, TP, FP, FN
- 정확도 = 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수 = (TN + TP)/(TN + FP + FN + TP)

### 정밀도 재현율
- 정밀도는 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터 비율(TP / (FP + TP))
- 실제 Positive 양성인 데이터를 Negative 잘못 판단하는 경우 : 스팸 메일
----
- 재현율은 실제값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터 비율(TP / (FN + TP))
- 실제 Negative 음성인 데이터를 Positive 잘못 판단하는 경우 : 암 진단, 금융사기 판별
#### **정밀도/재현율 트레이드 오프**
- 임계값을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다
- 상호 보완적인 평가 지표 이기 때문에 하나를 올리면 다른 하나는 떨어진다
- 임계값이 낮아질 수록 Positive로 예측할 확률이 높아짐. **재현율 증가**
- Estimator의 predict_proba()는 분류 결정 예측 확률을 반환
- precision_recall_curve() 임계값에 따른 정밀도 재현율의 변화값 제공

### F1 Score
- 정밀도와 재현율을 결합한 지표
- 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값
- f1_score()

### ROC AUC
- 이진 분류의 예측 성능 측정에서 중요하게 사용되는 지표
- 일반적으로 의학 분야
- ROC 곡선은 FPR이 변할 때 TPR이 어떻게 변하는지를 나타내는 곡선
- FPR을 X축, TPR을 Y축
- AUC값은 ROC 곡선 밑의 면적을 구한 것으로서 일반적으로 1에 가까울수록 좋은 수치
- TPR = TP / (FN + TP) 재현율은 민감도로도 불린다
- FPR은 실제 음성을 잘못 예측한 비율 - 실제는 Negative인데 Positive로 잘못 예측
- FPR = FP / (FP + TN)
- 임계값이 1이면 FPR 은 0, 0이면 1